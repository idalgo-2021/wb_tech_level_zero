# Тестовое задание L0 учебного курса 'Горутиновый golang' от техношколы WB

**Демонстрационный сервис с Kafka, PostgreSQL, кешем**

 ## Задание
 
 <details>
<summary>Формулировка задания:</summary>

Необходимо разработать демонстрационный сервис с простейшим интерфейсом, отображающий данные о заказе.

Данное задание предполагает создание небольшого микросервиса на Go с использованием базы данных и очереди сообщений. Сервис будет получать данные заказов из очереди (Kafka), сохранять их в базу данных (PostgreSQL) и кэшировать в памяти для быстрого доступа.

Что нужно сделать:

* Развернуть локально базу данных:

1. Cоздать новую базу данных для сервиса

2. Настроить пользователя: заведите пользователя и выдайте права на созданную БД

3. Создать таблицы: спроектируйте структуру для хранения полученных данных о заказах, ориентируясь на прилагаемую модель данных.

* Разработать сервис:

1. Написать приложение на Go, реализующее описанные ниже функции.

2. Разработать простейший интерфейс для отображения полученных данных по ID заказа.

3. Подключиться и подписаться на канал сообщений: настроить получение данных из брокера сообщений (Kafka).

4. Сохранять полученные данные в БД: при приходе нового сообщения о заказе, парсить его и вставлять соответствующую запись(и) в базу данных (PostgreSQL).

5. Реализовать кэширование данных в сервисе: хранить последние полученные данные заказов в памяти (например, в map), чтобы быстро выдавать их по запросу.

6. При перезапуске восстанавливать кеш из БД: при старте сервиса заполнять кеш актуальными данными из базы, чтобы продолжить обслуживание запросов без задержек.

7. Запустить HTTP-сервер для выдачи данных по ID: реализовать HTTP-эндпоинт, который по order_id будет возвращать данные заказа из кеша (JSON API). Если в кеше данных нет, можно подтягивать из БД.

* Разработать простой веб-интерфейс — страницу (HTML/JS), где можно ввести ID заказа и получить информацию о нём, обращаясь к вышеописанному HTTP API.

*Примечание: модель данных заказа (поля заказа, доставки, оплаты и товаров) прилагается в JSON-файле.*

Данные, приходящие из очереди, могут быть невалидными — необходимо предусмотреть обработку ошибок (например, игнорируйте или логируйте некорректные сообщения). В ходе реализации убедитесь, что при сбоях (ошибка базы, падение сервиса) данные не теряются — используйте транзакции, механизм подтверждения сообщений от брокера и т.д.

После реализации убедитесь, что:

1. Сервис подключается к брокеру сообщений (Kafka) и обрабатывает сообщения онлайн (можно написать скрипт-эмулятор отправки сообщений).

2. Кеш действительно ускоряет получение данных (например, при повторных запросах по одному и тому же ID).

3. HTTP-сервер возвращает корректные данные в формате JSON.

*Пример запроса:*

GET http://localhost:8081/order/<order_uid> должен вернуть JSON с информацией о заказе.

4. Интерфейс отображает данные понятным образом после ввода ID и нажатия кнопки.


**Результат**

По готовности сервиса снимите короткое видео работы интерфейса и вместе со ссылкой на репозиторий пришлите на проверку через личный кабинет.

Модель данных:

```
{
   "order_uid": "b563feb7b2b84b6test",
   "track_number": "WBILMTESTTRACK",
   "entry": "WBIL",
   "delivery": {
      "name": "Test Testov",
      "phone": "+9720000000",
      "zip": "2639809",
      "city": "Kiryat Mozkin",
      "address": "Ploshad Mira 15",
      "region": "Kraiot",
      "email": "test@gmail.com"
   },
   "payment": {
      "transaction": "b563feb7b2b84b6test",
      "request_id": "",
      "currency": "USD",
      "provider": "wbpay",
      "amount": 1817,
      "payment_dt": 1637907727,
      "bank": "alpha",
      "delivery_cost": 1500,
      "goods_total": 317,
      "custom_fee": 0
   },
   "items": [
      {
         "chrt_id": 9934930,
         "track_number": "WBILMTESTTRACK",
         "price": 453,
         "rid": "ab4219087a764ae0btest",
         "name": "Mascaras",
         "sale": 30,
         "size": "0",
         "total_price": 317,
         "nm_id": 2389212,
         "brand": "Vivienne Sabo",
         "status": 202
      }
   ],
   "locale": "en",
   "internal_signature": "",
   "customer_id": "test",
   "delivery_service": "meest",
   "shardkey": "9",
   "sm_id": 99,
   "date_created": "2021-11-26T06:22:19Z",
   "oof_shard": "1"
}
```
</details>
<br><br>



## Содержание

- [Использованные технологии](#used_tech)
- [Особенности реализации](#important_features)
- [Архитектура сервиса](#arch)
- [Структура проекта](#project_struct)
- [Установка и запуск](#installation_and_launch)



<a name="used_tech"><h2>Использованные технологии</h2></a>

* **Язык проекта**: Golang
    * **Логгер**:  zap logger(от Uber)
    * **Роутер**: HTTP роутер mux(от gorilla) 
    * **Горутины**
    * **gracefull shutdown**
* **БД**: PostgreSQL
* **Кэш**: Redis
* **Брокер сообщений**: Kafka
* **Визуализация состояния топиков Kafka**: Kafka UI
* **Документирование HTTP APi**: Swagger(https://github.com/swaggo)
* **Виртуализация**: Docker(Docker-compose)




<a name="important_features"><h2>Особенности реализации</h2></a>


⚠️ На мой взгляд, формулировка задания очень уж широкая, критерии оценки не обозначены. Попытки уточнить(в чате) интересовавшие меня требования ни к чему не привели. Ответы в стиле сделать как можно лучше я тоже не особенно понял, т.к. во-первых непрофессионал в Go, а во-вторых - улучшать и оптимизировать можно до бесконечности(ведь у нас нет требований, нет критериев). Но и максимально упрощать проект тоже не хочется. В виду этого, я решил принять следующие ограничения при реализации задачи.  

1. Данные сообщений хранятся в нескольких таблицах(orders, deliveries, payments, items). 

*Поскольку нам неизвестен профиль нагрузки системы и использования данных, то допустимым альтернативным вариантом хранения данных в БД выглядит вариант с хранением сообщений в виде строк или JSON. Во многих задачах такой подход будет намного более производительным. Так же, кеширование и получение из кэша заказов в строковом представлении выполняется сравнительно быстрее.*

2. Входящие сообщения(заказы) ищутся в системе по полю 'order_uid'. Если заказ уже имеется в системе, то сообщение не обрабатывается, но перекладывается в топик DLQ(Dead Letter Queue).

3. При чтении данных из Kafka, невалидные сообщения и сообщения, заказы из которых уже имеются в системе - перекладывается в специализированный Kafka-топик DLQ. Т.о. сообщения не теряются(даже с дублями и невалидные, но основной топик не содержит "мусора"). Это самая простая схема использования DLQ, но при необходимости её можно быстро изменить и адаптировать под требования.
    * Предполагается, что топик DLQ обрабатывается в отдельном порядке(в моем проекте эта обработка не реализована). 
    * Для невалидных и дублирующих сообщений, не предусмотрено дополнительных попыток записи в БД сервиса, они сразу же передаются в DLQ. Для всех остальных сообщений предусмотрено несколько попыток записи в систему(через увеличивающийся интервал времени). Данную механику тоже возможно улучшить, например расширить перечень ошибок которые требуют\не требуют повторных попыток. Но, механика в любом случае должна быть адекватна требованиям.

4. Валидация входящих сообщений реализована на основе пакета "github.com/go-playground/validator/v10". Не уверен, что подобный механизм максимально удобен, т.к. требует корректировки кода.

5. В системе предусматривается кэширование на базе Redis, но поскольку стратегия кэширования не определена, то:
    * Заказы хранятся в кэше в виде go-моделей и перед выдачей сериализуются в JSON.
    * Прогрев кэша(при запуске приложения) выполняется синхронно, чтобы к началу работы кэш уже был прогрет.
    * Прогрев кэша содержит простой механизм, заключающийся в том, что 100 заказов из БД загружаются в кэш.
    * При необходимости кэширования заказа, если его нет в кэше(например при создании нового заказа на основе входящего сообщения, из запроса по UID отсутствующего в кэше заказа) - в случае успешного его нахождения в БД, данный заказ кэшируется асинхронно. 
    * При асинхронном кэшировании не используются каналы ошибок, отправка метрик и т.п.

6. Проект предусматривает использование технологии Docker-виртуализации для запуска в отдельных контейнерах - БД(PostgreSQL), кэша(Redis), брокера сообщений(Kafka и Kafka UI). Сборку в Docker-контейнер самого приложения я не предусматривал(это довольно легко сделать при необходимости).

Для упрощения автоматизации сборки Docker-контейнеров создан соответствующий `Makefile`. 

7. Хотя пункт задания о разработке интерфейса для отображения полученных данных по ID заказа и кажется лишней, тем не менее простую html-стриничку я реализовал - см. каталог frontend. Однако, Поскольку в приложении используется swagger(доступен по http://<HOST>:<PORT>/swagger/index.html), то разработка специального фронтенд-инструмента для отображения полученных данных по ID заказа кажется лишней. Более того, для вывода результатов подходит любой браузер, любой инструмент типа Postman. 

8. В системе имеется несколько простейших unit-тестов, но нет интеграционных. *Сказать по правде, я не умею правильно писать тесты и потому оставил этот пункт незавершенным.*

-----


9. В приложении используется `.env`-файл для загрузки переменных окружения, которые в свою очередь используются приложением и в подготовке Docker-контейнеров.  

Пример заполнения `.env` см. в `.env.example`. Вы можете создать `.env` и скопировать содержимое `.env.example`.

*Наименования параметров 'говорящие' и не требуют специального описания.*  

При отсутствии `.env`-файла, параметры будут браться из конфигурации приложения 'config.go', что может вызвать некоторые трудности. Обращайте на это внимание.


10. В качестве интерфейса для просмотра содержимого заказа(как и требуется в задании) создана простая html страничка с небольшим скриптом - см. каталог `frontend`. В скрипте "захардкожен" URL для выполнения запроса(и хост и API ресурс), т.е. `http://localhost:10000/order/${uid}`. Это нужно иметь в виду, если вы запускаете http-сервер на другом порту и\или изменили соответствующий адрес ресурса(ручку).

11. Генератор сообщений(заказов) в Kafka - отдельное приложение(утилита) из каталога `cmd/order-producer/main.go`. Генератор генерирует только одно сообщение, причем с UID по умолчанию: OrderUID: "b563feb7b2b84b6trst". Таким образом, для генерации сообщений с другими идентификаторами, вам нужно изменить вручную данный параметр, либо слегка доработать генератор(сделать генерацию OrderUID - случайной).





<a name="arch"><h2>Архитектура сервиса</h2></a>

Приложение представляет сервис, обеспечивающий следующую требуемую в задании функциональность. 

Основные модули(*я пытался в 'Чистую архитектуру' и разделение ответственности между слоями-модулями*):

* Kafka-консьюмер(количество консьюмеров регулируется через переменные окружения).
* Kafka-хендлер - выполняет функцию валидатора входящих сообщений и передачу в сервисный слой(и прием-передачу результатов из сервисного слоя в Kafka-консьюмер).
* HTTP-сервер с шлюзом и маршрутизатором для обработки HTTP-запросов(вызова соответствующих HTTP-хендреров).
* HTTP-хендреры для вызова соответствующих методов сервисного слоя и обработки результатов.
* Сервисный слой - обрабатывает входящие запросы от хендлеров, отправляет соответствующие ответы, взаимодействует с кэшем и репозиторием приложения.
* Слой репозитория - обрабатывает запросы сервисного слоя и взаимодействует с БД.

```
flowchart LR
    K[Kafka] -->|Сообщения| C[Consumer]
    C --> S[Service Layer]
    S -->|Сохранение| DB[(PostgreSQL)]
    S -->|Кэширование| R[(Redis)]
    UI[HTTP API / Swagger / Frontend] --> S
```


<a name="project_struct"><h2>Структура проекта</h2></a>

```
.
├── cmd
│   ├── main
│   │   └── main.go           - точка входа
│   ├── order-producer
│   │   └── main.go           - генератор сообщений(заказов) для Kafka
│   └── tools
│       └── create_dlq_topic
│           └── main.go       - создание DLQ топика Kafka
├── docker-compose.yaml       - конфигурация сборки Docker-контейнеров внешних компонетов сервиса
├── docs
│   ├── docs.go
│   ├── swagger.json
│   └── swagger.yaml       - swagger документация HTTP API
├── frontend
│   ├── app.js
│   └── index.html         - фронтенд интерфейс для получения заказов по UID
├── go.mod
├── go.sum
├── internal
│   ├── app
│   │   └── app.go         - файл инициализации моделей приложения
│   ├── cache
│   │   └── cache.go       - методы кэша
│   ├── config
│   │   └── config.go        - конфигурация приложения      
│   ├── delivery
│   │   ├── http
│   │   │   ├── handler.go       - HTTP хендлеры
│   │   │   ├── handler_test.go  - .unit-тесты для HTTP хендлеров
│   │   │   └── helper.go        - вспомогательные функции HTTP хендлеров
│   │   └── kafkadelivery
│   │       ├── consumer.go      - код консьюмера(читателя) Kafka
│   │       ├── errors.go        - кастомные ошибки пакета для консьюмера
│   │       ├── event.go         - схема и функция валидации входящего сообщения
│   │       └── handler.go       - Kafka хендлер
│   ├── dto
│   │   └── dto.go               - модели, доступные хендлерам(HTTP хендлеры - для перемаппинга моделей сервиса)
│   ├── gateway
│   │   ├── gateway.go           -  HTTP-сервер
│   │   └── routes.go            - маршрутизатор HTTP-сервера
│   ├── orders
│   │   ├── errors.go            - ошибки домена заказов
│   │   └── models.go            - модели домена заказов
│   ├── repository
│   │   └── repository.go        - репозиторий для обработки запросов от сервиса обработки заказов
│   └── service
│       ├── orders_cache.go         - декларация интерфейсов кэша для сервиса
│       ├── orders_helpers.go       - хелперы для сервисного слоя
│       ├── orders_repository.go    - декларация интерфейсов для репозитория
│       ├── orders_service.go       - декларация публичных интерфейсов сервиса обработки заказов
│       ├── orders_service_impl.go  - имплементация функций сервисного слоя
│       └── orders_service_test.go  - unit-тесты для сервисного слоя
├── Makefile      - скрипты автоматизации
├── migrations
│   └── 001_create_order_tables.sql - скрипт создания структур таблиц БД(модель данных для PostgreSQL)
├── pkg
│   ├── db
│   │   └── postgres.go    - инициализатор подключения к PostgreSQL
│   ├── logger
│   │   └── logger.go      - обертка над zap, логгер сервиса 
│   └── redisclient
│       └── redisclient.go - инициализатор подключения клиента Redis
└── Readme.md

```


<a name="installation_and_launch"><h2>Установка и запуск</h2></a>


1. Склонируйте репозиторий. 

```
git clone https://github.com/idalgo-2021/wb_tech_level_zero.git
```

2. Установите необходимые зависимости(выполнить из корня проекта).

```
go mod tidy
```

3. Подготовьте '.env' - файл.

Создайте в корне проекта файл '.env' и заполните его по примеру '.env.example'(можно скопировать его содержимое, оно также скорее всего будет рабочим).  

4. Создайте необходимые для работы приложения Docker-контейнеры(выполнить в корне проекта).

```
make up
```

5. Создайте основной топик Kafka внутри контейнера(выполнить в корне проекта).

```
sudo docker exec -it kafka /bin/bash
kafka-topics.sh --create --topic orders --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
```

6. Создайте топик kafka для DLQ(выполнить в корне проекта).

```
go run ./cmd/tools/create_dlq_topic
```

7. Запустите приложение(выполнить в корне проекта).

```
go run ./cmd/main/main.go
```
Пример лога при полностью успешном старте:

```
mikha@basta3:~/my_development/my_go/wb_tech/wb_tech_level_zero$ go run ./cmd/main/main.go
{"level":"info","ts":1755341014.0010533,"caller":"main/main.go:42","msg":"Configuration loaded"}
{"level":"info","ts":1755341014.0237105,"caller":"logger/logger.go:46","msg":"Starting HTTP server on 127.0.0.1:10000","service":"wb_tech"}
{"level":"info","ts":1755341014.0237777,"caller":"logger/logger.go:46","msg":"HTTP server is starting to listen","service":"wb_tech"}
{"level":"info","ts":1755341014.023764,"caller":"logger/logger.go:46","msg":"Warming up Redis order cache...","service":"wb_tech"}
{"level":"info","ts":1755341014.0237963,"caller":"logger/logger.go:46","msg":"Starting Kafka consumer...","service":"wb_tech"}
{"level":"info","ts":1755341014.0239084,"caller":"logger/logger.go:46","msg":"Worker 1 started","service":"wb_tech"}
{"level":"info","ts":1755341014.0238338,"caller":"logger/logger.go:46","msg":"Warming up cache...","service":"wb_tech"}
{"level":"info","ts":1755341014.0239651,"caller":"logger/logger.go:46","msg":"Worker 0 started","service":"wb_tech"}
{"level":"info","ts":1755341014.0356164,"caller":"logger/logger.go:46","msg":"Cache warmup completed","service":"wb_tech","count":2,"failed":0}
```

8. Для генерации и отправки сообщения в Kafka(выполнить в корне проекта).

```
go run cmd/order-producer/main.go
```

9. Пример использования рабочих ресурсов(ручек) при успешном запуске приложения:

```
   # /order/order_uid - основная ручка по заданию(документирована в swagger)
   http://localhost:10000/order/b563feb7b2b84b6test

   # /orders - дополнительная ручка, возвращающая список заказов, без перечня Items(недокументирована в swagger, данные запрашиваются напрямую из БД, без использования кэша)
   http://localhost:10000/orders

   # /swagger/index.html - swagger описание HTTP API приложения в формате OpenAPI
   http://localhost:10000/swagger/index.html

   # [port]/ui/ - ручка Kafka UI, позволяющая визуализировать состояние топиков Kafka
   http://localhost:8080/ui/

   # После генерации сообщений(заказов) в кафку и записи их в БД, по их UID у вас так же должен работать и фронтенд `frontend/index.html`

```

